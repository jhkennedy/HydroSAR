{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<hr>\n",
    "<font size=\"6\"> <b>Archive Watermaps</b></font>\n",
    "\n",
    "<font size=\"5\">  Transfer successful HyP3 jobs to an S3 bucket </font>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import relevant python packages\n",
    "import json\n",
    "from os import environ\n",
    "from tqdm import tqdm\n",
    "\n",
    "import boto3\n",
    "import hyp3_sdk\n",
    "from boto3.s3.transfer import TransferConfig\n",
    "\n",
    "#specify which boto3 resource we will use\n",
    "S3 = boto3.resource('s3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select configuration file and decide if prompt is True."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config_file = '/Users/jrsmale/GitHub/hyp3-nasa-disasters/data_management/hkh_watermaps.json'\n",
    "prompt = False\n",
    "\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "project_name = config[\"project_name\"]\n",
    "target_bucket = config[\"transfer_spec\"][\"target_bucket\"]\n",
    "target_prefix = config[\"transfer_spec\"].get(\"target_prefix\", project_name)\n",
    "if prompt:\n",
    "    project_name = input(f'HyP3 project name [{project_name}]: ') or project_name\n",
    "    target_bucket = input(f'Destination bucket: [{target_bucket}]') or target_bucket\n",
    "    target_prefix = input(f'Destination prefix: [{target_prefix}]') or target_prefix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Connect to HyP3 using HyP3 SDK to find a list of HyP3 jobs that are associated with our project's name."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyp3 = hyp3_sdk.HyP3(\n",
    "    config['host'], username=environ.get('EDL_USERNAME'), password=environ.get('EDL_PASSWORD'), prompt=prompt\n",
    ")\n",
    "jobs = hyp3.find_jobs(name=project_name)\n",
    "print('\\n' + project_name)\n",
    "print(jobs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find the contents of our S3 bucket."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "project_contents = set()\n",
    "for o in S3.Bucket(target_bucket).objects.filter(Prefix=f'{target_prefix}/'):\n",
    "        project_contents.add(o.key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we will check all succeed jobs and find which ones aren't represented yet in our S3 bucket. This prevents us from uploading the same files repeatedly to the cloud."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "objects_to_copy = []\n",
    "for job in tqdm(jobs):\n",
    "    if not job.succeeded():\n",
    "        continue\n",
    "    source_bucket = job.files[0]['s3']['bucket']\n",
    "    zip_key = job.files[0]['s3']['key']\n",
    "    for ext in config[\"transfer_spec\"][\"extensions\"]:\n",
    "        source_key = zip_key.replace('.zip', ext)\n",
    "        target_key = source_key.replace(job.job_id, target_prefix)\n",
    "        if target_key not in project_contents:\n",
    "            objects_to_copy.append({\n",
    "                'source_bucket': source_bucket,\n",
    "                'source_key': source_key,\n",
    "                'target_bucket': target_bucket,\n",
    "                'target_key': target_key,\n",
    "            })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now copy these new files to our S3 bucket."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'\\nFound {len(objects_to_copy)} new files to copy to s3://{target_bucket}/{target_prefix}/')\n",
    "if prompt:\n",
    "    input('Press Enter to continue, Ctrl-c to cancel')\n",
    "\n",
    "chunk_size = 104857600\n",
    "for object_to_copy in objects_to_copy:\n",
    "        bucket = S3.Bucket(target_bucket)\n",
    "        copy_source = {'Bucket': source_bucket, 'Key': source_key}\n",
    "        transfer_config = TransferConfig(multipart_threshold=chunk_size, multipart_chunksize=chunk_size)\n",
    "        bucket.copy(CopySource=copy_source, Key=target_key, Config=transfer_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}